"""CLI for JDC utilities"""

import click
from jdc_utils.submission import CoreMeasures
from jdc_utils.transforms import read_df, run_transformfile
from jdc_utils.transforms.deidentify import shift_dates,replace_ids,init_version_history_all
import os
import pandas as pd
import glob 
from pathlib import Path 
import yaml
import sys 

# overall CLI
@click.group()
def cli():
    """CLI for JDC utilities"""
    pass

# TODO: make CLI more like 

# 

@click.command(
    name="replace-ids",
    help=''' 
        This function is used to replace (and map) local ids assigned at the time of data collection
        with separate ids generated by the DASC and given to hubs.

        Replacing local ids with JDC specific ideas reduces the risk of hub and participant identification.

        The mapped local to JDC ids are intended to be seen only by hub staff. 
        '''
)
@click.option(
    "--file-path",
    "file_paths",
    help="Path to a file with locals/old ids to be replaced. Can specify multiple files if need to replace ids across multiple files",
    multiple=True,
    required=True,
)
@click.option(
    "--id-file",
    help="Path to where the generated ids (created by the MAARC and distributed to hubs) exist",
    required=True,
)
@click.option("--id-column", 
    help="""
        Name of column across files specified with old (or local) ids
        If none specified, defaults to first level (ie 0) pandas dataframe index
        """
) 
@click.option("--history-path",
 help='Git bare repo set up -- ie the "remote url" for sharing mapped ids',
 required=True)
def replace_ids(file_paths, id_file,id_column,history_path):
    for file_path in file_paths:
        #glob.glob allows support for both wildcards (*) and actual file paths
        file_paths = glob.glob(file_path) #if not a regex, will just return the filepath within list
        for file_path in file_paths:
            sourcedf = read_df(file_path)
            targetdf = replace_ids(sourcedf, id_file, map_file, map_url, id_column)
            targetdf.to_csv(f"tmp/jdc/{Path(file_path).stem}-replacedids.csv",index=False)
            click.echo(f"Replaced local with jdc ids in: {os.path.join(os.getcwd(),new_file_dir)}")

@click.command(
    name="shift-dates",
    help=''' 
        This function takes a specified date field and shifts them around a specified number of days (ie shift amount).
        This shifted amount is selected randomly within an interval of the previous 182 days and next 182 days.
        This shift amount is fixed within each individual such that the intervals between dates are retained to provide the 
        capability to calculate derived variables such as days from a given visit/timepoint (e.g., days from baseline or 
        days from release). 

        As with the replace id function, the mappings (i.e., id to the random # of days shifted) is stored in a separate file
        to reduce deductive disclosure risk from PII linkage with date variables.

        However, by storing this shift amount (rather than randomly shifting at each data update, 
        the exact dates can be recovered
        simply by subtracting this added random amount to the shifted date.

        '''
)
@click.option(
    "--file-path",
    "file_paths",
    help="""
    Path to a file with dates to be shifted. 
    Can specify multiple files if column name is the same across files
    """,
    multiple=True,
    required=True,
)
@click.option("--id-column",
 help="Name of column across files specified ids.",
 required=True)
@click.option("--date-column", 
    help="Name of date column(s) to be shifted",
    required=True,
    multiple=True)
@click.option("--history-path",
 help='Git bare repo set up -- ie the "remote url" for sharing mapped ids',
 required=True)
def shift_dates(id_column,date_columns,history_path):
    for file_path in file_paths:
        #glob.glob allows support for both wildcards (*) and actual file paths
        file_paths = glob.glob(file_path) #if not a regex, will just return the filepath within list
        for file_path in file_paths:
            sourcedf = read_df(file_path)
            targetdf = replace_ids(sourcedf, id_file, map_file, map_url, id_column)
            targetpath = f"tmp/jdc/{Path(file_path).stem}-shifteddates.csv"
            targetdf.to_csv(targetpath,index=False)
            click.echo(f"Shifting dates and saving to: {targetpath}")


@click.command(
    ''' 
    This input file transforms a given dataset with a variety of functions or any function 
    available within pandas that has an "inplace" argument. 

    Most commonly, this will entail renaming variables and values to match the data model
    schema in order to pass validation (see the jdc-utils validate function)

    ''' 
)
@click.option(
    "--file-path",
    "file_paths",
    help="Path to the given dataset file. Can specify multiple files if same transform file used across multiple data files.",
    multiple=True,
    required=True,
)
@click.option("--transform-file", help="Path to the given transform file")
def transform(transform_file, file_paths):

    # read in and run transforms -- right now currently using pandas -- may want to migrate to petl
    # for consistency with validation as it uses petl to read in and type conversions may be different.
    # alternatively, we could use the pandas plugin for frictionless but it is experimental.
    #click.echo("STARTING")
    for file_path in file_paths:
        #glob.glob allows support for both wildcards (*) and actual file paths
        file_path_with_glob_regexs = glob.glob(file_path) #if not a regex, will just return the filepath within list
        
        print(f"Applying {transform_file} to:")
        print(','.join(file_path_with_glob_regexs))

        for file_path_glob in file_path_with_glob_regexs:
            sourcedf = read_df(file_path_glob)
            targetdf = run_transformfile(df, transform_file)
            targetpath = f"tmp/jdc/{Path(file_path).stem}-transformed.csv"
            targetdf.to_csv(targetpath,index=False)
            click.echo(f"Transformed file saved to {targetdf}")


@click.command()
@click.option(
    "--filepath",
    help="Path to directory where dataset file(s) live",
)
def validate(filepath):
    os.chdir(filepath)
    core_measures = CoreMeasures('.')
    core_measures.validate(write_to_file=True)

    if core_measures.report["valid"]:
        click.echo(
            f"Congrats! Your file(s) -- {','.join(core_measures.resource_names)} ---  passed validation!\n"
        )
        click.echo("If you're happy with them, you can proceed with submission.")
    else:
        click.echo(
            "\n\n"
            f"One or more of the core measure files need some corrections.\n"
            f"Take a look below at the error report table below to correct.\n"
            f"We also wrote several useful files derived from the validation report to help in\n"
            "the curation process with the suffix 'report':\n"
            "----------------------------------------------------------------------\n"
            "----------------------------------------------------------------------\n"
        )
        click.echo(core_measures.report.to_summary())

@click.command()
@click.option("--history-path",default=Path(".").as_posix()/"mappings-history")
def init_history():
    init_version_history_all(history_path)


# deidentification commands
cli.add_command(init_history, name="init-deidentify-history")
cli.add_command(replace_ids, name="replace-ids")
cli.add_command(shift_dates, name="shift-dates")

#validation
cli.add_command(validate, name="validate")

#pipeline
cli.add_command(transform, name="transform")
cli.add_command(run_all,name="run-all")

if __name__ == "__main__":
    cli()
