# Utilities for de-identifying data, transforming data, and validating data for JDC submissions

> **CAUTION: README UNDER CONSTRUCTION**


The JDC utilities provide tools for de-identifying, harmonizing, and validating data according to JCOIN data
commons specifications and standards.

This repository provides python-based functions to achieve these goals and exposes a command line interface
to quickly (1) initiate your configuration and (2) run deidentification, transformations, and validation.

These tools are (and can be) leveraged in specific JCOIN hub workflows at various points in the data curation workflow.

## Usage

There are several options to use these jdc utilities.


## Use the command line interface with configuration files that store the input parameters.

1. Using individual workflow, transform files into specifications layed out by schemas (e.g., Core Measure data dictionaries).

2. Run the command line utilities to run deidentify, package, and validation.

```bash
cd <folder name where you store data>
```

Create a configuration file and initiate version control mappings:

```bash
jdc-utils init
```

Run the deidentification process (shift_dates and replace_ids) on the specified filepath:

```bash
jdc-utils run
```

> NOTE: need to add a path to a transform script option.

### Use these tools directly in python scripts.
TO ADD


## Workflow steps

### deidentification

#### replace ids

This function is used to replace (and map) local ids assigned at the time of data collection
with separate ids generated by the DASC and given to hubs.

Replacing local ids with JDC specific ideas reduces the risk of hub and participant identification.

The mapped local to JDC ids are intended to be seen only by hub staff.

#### shift dates

This function takes a specified date field and shifts them around a specified number of days (ie shift amount).
This shifted amount is selected randomly within an interval of the previous 182 days and next 182 days.
This shift amount is fixed within each individual such that the intervals between dates are retained to provide the
capability to calculate derived variables such as days from a given visit/timepoint (e.g., days from baseline or
days from release).

As with the replace id function, the mappings (i.e., id to the random # of days shifted) is stored in a separate file
to reduce deductive disclosure risk from PII linkage with date variables.

However, by storing this shift amount (rather than randomly shifting at each data update,
the exact dates can be recovered
simply by subtracting this added random amount to the shifted date.

### transform data
Transforming data currently leverages functions written with pandas and pandas-flavor decorator.

It is a simple two step process:

1. Read in data file to a data frame
    - `transforms.read_df(filepath)` function from specified data file path
2. Transform data frame to JDC properties and values
    - `transforms.run_transformfile(df,transformfile)` function from the transform functions specified in a transforms.yaml file (which itself is specified in the config.yaml file) on the dataframe


This transformfile contains a way to specify transforms within a simple text file called a "yaml" file:

Specifies the function, paramater name and parameter input
to be run on input data in a yaml file:

```yaml
<name of registered/valid pandas function>:
    <name of function parameter>: <paramter input (this may be a string, list, or dictionary)>
```

Examples:

Example native pandas functions :

*Rename columns:*

```yaml
rename:
    columns:
        d4_b: gender
        record_id: submitter_id
```

is intended to run:

```python
df.rename(columns={"d4_b": "gender", "record_id": "submitter_id"})
```
Custom registered functions leverage pandas-flavor
module to directly make pandas methods to the
pd.DataFrame class. Many of these registered
functions are in the transforms.py, but does not necessarily
need to be restricted to only this file.

Example custom registered functions:

*Rename columns:*
```yaml
rename_columns:
  from_name_to_name:
    d4_b: gender
    record_id: submitter_id
```
is intended to run the function

```python
df.rename_columns(from_name_to_name={"d4_b": "gender", "record_id": "submitter_id"})
```


*Convert a date field to a new quarter field:*

```yaml
to_quarter:
    from_date_name_to_quarter_name:
        date_recruited: quarter_recruited
```

is intended to run the function

```python
df.to_quarter(from_date_name_to_quarter_name={"date_recruited": "quarter_recruited"})
```


### validate data
