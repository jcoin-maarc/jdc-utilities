{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing for JDC uploads\n",
    "\n",
    "This notebook contains the code that will be refactored/packaged into data packaging/upload functions\n",
    "\n",
    "1. Creating joint dataset\n",
    "2. writing core measures to Stata and SPSS files\n",
    "3. compress\n",
    "4. map to sheepdog\n",
    "5. upload both sheepdog and core measure files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from jdc_utils.utils import zip_package\n",
    "from jdc_utils.encoding import core_measures as encodings\n",
    "from dataforge.frictionless.categoricals import table_encode\n",
    "from frictionless import Resource,Package,transform\n",
    "\n",
    "from jdc_utils.schema import core_measures as schemas\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "jdc_utils_pwd = Path().resolve().parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(jdc_utils_pwd)\n",
    "datapackage_paths = [\n",
    "    path.resolve() \n",
    "    for path in Path().glob(\"../*/*/core-measures-*/\") \n",
    "    if path.is_dir() and not 'joint' in path.name\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('C:/Users/kranz-michael/projects/jcoin-chestnut/tmp/core-measures-chestnut'),\n",
       " WindowsPath('C:/Users/kranz-michael/projects/jcoin-nyu/tmp/core-measures-nyu'),\n",
       " WindowsPath('C:/Users/kranz-michael/projects/jcoin-uky/tmp/core-measures-uky'),\n",
       " WindowsPath('C:/Users/kranz-michael/projects/jcoin-yale-hiv/tmp/core-measures-yale_hiv')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapackage_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make combined data package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(jdc_utils_pwd)\n",
    "jointdatapath = jdc_utils_pwd/'tmp'/'core-measures-joint'\n",
    "jointdatapath.mkdir(exist_ok=True,parents=True)\n",
    "\n",
    "schemapath = jointdatapath.joinpath('schemas')\n",
    "schemapath.mkdir(exist_ok=True,parents=True)\n",
    "\n",
    "num_valid_packages = sum([json.loads(p.joinpath('report.json').read_text())['valid'] \n",
    "    for p in datapackage_paths])\n",
    "assert num_valid_packages==len(datapackage_paths)\n",
    "\n",
    "# write resources\n",
    "for resource_name in ['baseline','time-points']:\n",
    "\n",
    "    resource_schema = getattr(schemas,resource_name.replace('-','')) # timepoints v time-points\n",
    "    resource_schema.to_json(schemapath/(resource_name+'.json'))\n",
    "\n",
    "    source_paths = [(p/'data'/f\"{resource_name}.csv\").as_posix() for p in datapackage_paths]\n",
    "    source = Resource(path=source_paths,schema=resource_schema)\n",
    "    source.write(jointdatapath/'data'/f'{resource_name}.csv')\n",
    "\n",
    "    target_spss = transform(source,steps=[table_encode(encodings.fields,encodings.reserve['spss'])])\n",
    "    target_stata = transform(source,steps=[table_encode(encodings.fields,encodings.reserve['stata'])])\n",
    "    target_spss.write(jointdatapath/'data'/(resource_name+\".sav\"))\n",
    "    target_stata.write(jointdatapath/'data'/(resource_name+\".dta\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"resources\": [\\n    {\\n      \"name\": \"baseline\",\\n      \"path\": \"data/baseline\"\\n    },\\n    {\\n      \"name\": \"time-points\",\\n      \"path\": \"data/time-points\"\\n    }\\n  ],\\n  \"title\": \"Cross-hub dataset\",\\n  \"description\": \"A combined data package of all submitted hub data to-date\"\\n}'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init Package\n",
    "os.chdir(jointdatapath.parent)\n",
    "package = Package(\n",
    "    title=\"Cross-hub dataset\",\n",
    "    description=\"A combined data package of all submitted hub data to-date\",\n",
    "    resources=[Resource(name=resource,path=f'data/{resource}')\n",
    "         for resource in ['baseline','time-points']]\n",
    ")\n",
    "package.to_json('data-package.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Stata and SPSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(jdc_utils_pwd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "core-measures-chestnut\n",
      "-->baseline\n",
      "-->time-points\n",
      "core-measures-nyu\n",
      "-->baseline\n",
      "-->time-points\n",
      "core-measures-uky\n",
      "-->baseline\n",
      "-->time-points\n",
      "core-measures-yale_hiv\n",
      "-->baseline\n",
      "-->time-points\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for path in datapackage_paths:\n",
    "    os.chdir(path)\n",
    "    report_path = Path('report.json')\n",
    "    if report_path.exists():\n",
    "        report = json.loads(report_path.read_text()) #this is a cherry picked version just to indicate whether datapackage is valid\n",
    "        package = Package('data-package.json')\n",
    "    else:\n",
    "        report = {'valid':False}\n",
    "    if report['valid']:\n",
    "        print(package['name'])\n",
    "        #write stata and spss\n",
    "        for source in package['resources']:\n",
    "            print(f\"-->{source['name']}\")\n",
    "            source_path = Path(source['path'])\n",
    "            target_spss = transform(source,steps=[table_encode(encodings.fields,encodings.reserve['spss'])])\n",
    "            target_stata = transform(source,steps=[table_encode(encodings.fields,encodings.reserve['stata'])])\n",
    "            target_spss_params = target_spss.write(source_path.with_suffix(\".sav\"))\n",
    "            target_stata_params = target_stata.write(source_path.with_suffix(\".dta\"))\n",
    "    else:\n",
    "        print(f\"{path.stem} is not valid or report.json not generated so skipping stata/spss generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compress to directory\n",
    "for path in datapackage_paths:\n",
    "    zip_path = jdc_utils_pwd/'tmp'\n",
    "    zip_path.mkdir(exist_ok=True)\n",
    "    zip_package(path,jdc_utils_pwd/'tmp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jdc-utils",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8703766e0eea0266513ec6bdab0dac9f88eac8cefc00ed0b139b384718afabe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
